\documentclass[11pt,a4paper]{article}
%以下为所使用的宏包
\usepackage{ulem}%下划线
\usepackage{amsmath,amsfonts,amssymb,amsthm,amsbsy}%数学符号
\usepackage{graphicx}%插入图片
\usepackage{booktabs}%三线表
%\usepackage{indentfirst}%首行缩进
\usepackage{tikz}%作图
\usepackage{appendix}%附录
\usepackage{array}%多行公式/数组
\usepackage{makecell}%表格缩并
\usepackage{siunitx}%SI单位--\SI{number}{unit}
\usepackage{mathrsfs}%数学字体
\usepackage{enumitem}%列表间距
\usepackage{multirow}%列表横向合并单元格
\usepackage[colorlinks,linkcolor=red,anchorcolor=blue,citecolor=green]{hyperref}%超链接引用
\usepackage{float}%图片、表格位置排版
\usepackage{pict2e,keyval,fp,diagbox}%带有斜线的表格
\usepackage{fancyvrb,listings}%设置代码插入环境
\usepackage{minted}%代码环境设置
\usepackage{fontspec}%字体设置
\usepackage{color,xcolor}%颜色设置
\usepackage{titlesec} %自定义标题格式
\usepackage{tabularx}%列表扩展
\usepackage{authblk}%titlepage作者信息
\usepackage{nicematrix}%更好的矩阵标定
\usepackage{fbox}%更多浮动体盒子
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}

%以下是页边距设置
\usepackage[left=0.5in,right=0.5in,top=0.81in,bottom=0.8in]{geometry}

%以下是段行设置
\linespread{1.4}%行距
\setlength{\parskip}{0.1\baselineskip}%段距
\setlength{\parindent}{2em}%缩进


%其他设置
\numberwithin{equation}{section}%公式按照章节编号
\newenvironment{point}{\raggedright$\blacktriangleright$}{}
\newenvironment{algorithm}[1]{\vspace{12pt} \hrule\hrule \vspace{3pt} \noindent\textbf{\color[HTML]{E63F00}Algorithm } \,\textit{#1} \vspace{3pt} \hrule\vspace{6pt}}{\vspace{6pt}\hrule\hrule \vspace{12pt}} % 算法伪代码格式环境


%代码环境\lst设置
\definecolor{CodeBlue}{HTML}{268BD2}
\definecolor{CodeBlue2}{HTML}{0000CD}
\definecolor{CodeGreen}{HTML}{2AA1A2}
\definecolor{CodeRed}{HTML}{CB4B16}
\definecolor{CodeYellow}{HTML}{B58900}
\definecolor{CodePurPle}{HTML}{D33682}
\definecolor{CodeGreen2}{HTML}{859900}
\lstset{
    basicstyle=\tt,%字体设置
    numbers=left, %设置行号位置
    numberstyle=\tiny\color{black}, %设置行号大小
    keywordstyle=\color{black}, %设置关键字颜色
    stringstyle=\color{CodeRed}, %设置字符串颜色
    commentstyle=\color{CodeGreen}, %设置注释颜色
    frame=single, %设置边框格式
    escapeinside=`, %逃逸字符(1左面的键)，用于显示中文
    %breaklines, %自动折行
    extendedchars=false, %解决代码跨页时，章节标题，页眉等汉字不显示的问题
    xleftmargin=2em,xrightmargin=2em, aboveskip=1em, %设置边距
    tabsize=4, %设置tab空格数
    showspaces=false, %不显示空格
    emph={TRUE,FALSE,NULL,NAN,NA,<-,},emphstyle=\color{CodeBlue2}, %其他高亮}
}


%节标题格式设置
\titleformat{\section}[block]{\large\bfseries}{Problem \arabic{section}}{1em}{}[]
\titleformat{\subsection}[block]{}{    \arabic{section}.(\alph{subsection})}{1em}{}[]
% \titleformat{\subsubsection}[block]{\normalsize\bfseries}{    \arabic{subsection}-\alph{subsubsection}}{1em}{}[]
% \titleformat{\paragraph}[block]{\small\bfseries}{[\arabic{paragraph}]}{1em}{}[]


% \titleformat{\sectioncommand}[shape]{format}{title-label}{sep}{before-title}[after-title]



% 中文字号
% 初号42pt, 小初36pt, 一号26pt, 小一24pt, 二号22pt, 小二18pt, 三号16pt, 小三15pt, 四号14pt, 小四12pt, 五号10.5pt, 小五9pt


\begin{document}

\begin{center}\thispagestyle{plain}

{\LARGE\textbf{Stat450 - 1 | 2024 Fall}}

{\Large\textbf{Final Exam}}

Tuorui Peng\footnote{TuoruiPeng2028@u.northwestern.edu}
\end{center}

\thispagestyle{myheadings}\markright{Compiled using \LaTeX}
\pagestyle{myheadings}\markright{Tuorui Peng}





  


\section{}

\subsection{}

Since $ X_i $ are i.i.d. r.v. with finite variance, we have
\begin{align*}
    \mathbb{E}\left[ \bar{X} _g\right] = \mu, \quad \text{Var}\left[ \bar{X} _g\right] \leq \dfrac{ \sigma ^2 }{ k }  
\end{align*}


\begin{align*}
    \mathbb{P}\left( \bar{X}_g -\mu \geq \dfrac{ 2\sigma  }{ \sqrt{k} }  \right) \leq & \mathbb{P}\left( (\bar{X}_g -\mu)^2 \geq \dfrac{ 4\sigma ^2 }{ k }  \right)   
    \leq  \dfrac{ var(\bar{X}_g) }{ 4\sigma ^2/k }
    \leq \dfrac{ 1 }{ 4 }  
\end{align*}

\subsection{}
With $ \hat{\mu }:= \mathrm{ median }(\bar{X}_1,\ldots,\bar{X}_G)  $, we have
\begin{align*}
    \mathbb{P}\left( \hat{\mu }-\mu \geq 2\sigma /\sqrt{k} \right) =& \mathbb{P}\left( \text{less than half of }\bar{X}_g \geq \mu +2\sigma /\sqrt{k} \right) 
\end{align*}
thus we consider the events $ A_g:= \{\bar{X}_g \geq 2\sigma /\sqrt{k}\} $ with $ \mathbf{1}(A_g) \sim \mathrm{Bin}(p) $ for some $ p\in[0,1] $. Using the result from (a), we further have $ p\leq 1/4 $.

Since $ \bar{X}_g $ are i.i.d., we have
\begin{align*}
    \mathbb{P}\left( \hat{\mu }-\mu \geq 2\sigma /\sqrt{k} \right) \leq & \mathbb{P}\left( \mathrm{Bin}(G,p) \geq G/2 \right)
    \leq  \mathbb{P}\left( \mathrm{Bin}(G,1/4) \geq G/2 \right) 
\end{align*}


\subsection{}
Note that $ \mathrm{ Bin }(G,1/4)  $ is sub-gaussian with $ \sigma  $ at most $ \sqrt{G}/2 $, we thus have
\begin{align*}
    \mathbb{P}\left( \mathrm{Bin}(G,1/4) \geq G/2 \right) =& \mathbb{P}\left( \mathrm{Bin}(G,1/4) -G/4 \geq G/4 \right)
    \leq  \exp\left( -\dfrac{ G^2 }{ 8G } \right)
    = \exp\left( -\dfrac{ G }{ 8 } \right) = \delta 
\end{align*}
then we substitute $ k=n/G = \dfrac{ n  }{ 8\log 1/\delta  }  $ to result in (b) to obtain
\begin{align*}
    \mathbb{P}\left( \hat{\mu } -\mu \geq 4\sigma \sqrt{\dfrac{ 2\log (1/\delta ) }{ n } } \right) \leq \delta  
\end{align*}

\subsection{}
Denote $ t = 4\sigma \sqrt{\dfrac{ 2\log (1/\delta ) }{ n } }  $, which yields
\begin{align*}
    \mathbb{P}\left( \hat{\mu } -\mu \geq t \right) \leq \delta = e^{-\frac{ t^2 }{ 2 (4\sigma /\sqrt{n})^2 } } 
\end{align*}
and also we should have a similar lower bound of the same form. So $ \hat{\mu } $ is indeed sub-gaussian with parameter at most $ \sim 4\sigma /\sqrt{n} $.



\section{}

% The proof is in Vershynin's book, Theorem 0.0.4. Here is a sketch of the proof.

% First we work on a Lemma: for any $ x\in P $, where $ P = \mathrm{conv}(x_1,\ldots,x_N) $ being the polytope, we have 
% \begin{align*}
%     \left\Vert x- \dfrac{ 1 }{ k } \sum_{i=1}^k x_i \right\Vert  \leq \dfrac{ 1 }{ \sqrt{k} } ,\quad \text{for some } \{x_i\}\subset P,\,\forall k\in [N]
% \end{align*}
% The proof is as follows:
% \begin{proof}
%     Note that for such polytope, for any $ x\in P $ we can always express it as (using Carahtéodory's theorem)
%     \begin{align*}
%         x = \sum_{i=1}^N \lambda _ix_i,\quad \sum_{i=1}^N \lambda _i = 1,\,\lambda _i\geq 0
%     \end{align*}
    
%     Consider an r.v. $ Z = x_i $ w.p. $ \lambda _i $, we have
%     \begin{align*}
%         \mathbb{E}\left[ Z \right] = x 
%     \end{align*}
%     then we create $ k $ copies of $ Z $, denoted as $ Z_1,\ldots,Z_k $, and we have
%     \begin{align*}
%         \mathbb{E}\left\Vert x- \dfrac{ 1 }{ k } \sum_{i=1}^k Z_i \right\Vert _2^2 =&  var(\dfrac{ 1 }{ k } \sum_{i=1}^k Z_i)\\
%         =& \dfrac{ 1 }{ k }var(Z)\\
%         \leq & \dfrac{ 1 }{ k } 
%     \end{align*}
%     since $ Z \in P $ is bounded by $ 1 $. Then since $ Z_i $ takes value in $ \{x_1,\ldots,x_N\} $, then there should always exist some realization of $ Z_i $ as $ Z_i = \text{some vertice} $ that satisfies the inequality.
% \end{proof}

% Using the Lemma, we can just choose $ k=\lceil 1/\varepsilon ^2 \rceil $ and obtain that for any $ x\in P $, we have
% \begin{align*}
%     \exists \{x_i\}_{i=1}^k\subset P,\, \left\Vert x- \dfrac{ 1 }{ k } \sum_{i=1}^k x_i \right\Vert  \leq \dfrac{ 1 }{ \sqrt{k} } \leq \varepsilon  
% \end{align*}
% so such $ \{\dfrac{ 1 }{ k }\sum_{i=1}^k x_i: x_i\in\text{ vertices of }P\}  $ set is a $ \varepsilon  $ covering of $ P $, which has size at most $ N^k = N^{\lceil 1/\varepsilon ^2 \rceil} $. 
It suffice to bound the card of packing set $ \mathcal{M}:=\mathcal{M}(P,\varepsilon ,\left\Vert \, \cdot \,  \right\Vert _2) $ since we have the relation between packing and covering set: 
\begin{align*}
    \left\vert \mathcal{M}(P,2\varepsilon ,\, \cdot \, ) \right\vert\leq \left\vert \mathcal{N}(P,\varepsilon ,\, \cdot \, ) \right\vert \mathop{ \leq }\limits^{(i)}  \left\vert \mathcal{M}(P,\varepsilon ,\, \cdot \, ) \right\vert
\end{align*}
We do so by the following steps:

\begin{enumerate}[topsep=2pt,itemsep=2pt]
    \item We first prove the following lemma (MJW Exercise 2.11 (b) but just up to constant)
        \begin{lemma}\label{lem:1}
        Given a sequence of i.i.d. $ N(0,1) $ guassian r.v. of size $ n $: $ \Xi=\{\xi _i\}_{i=1}^n $, we have
        \begin{align*}
            \mathbb{E}\left[ \sup_{\xi _i\in\Xi} \xi _i \right] \geq & \sqrt{\log n} \mathbb{P}\left( \exists\, \xi _i\in \Xi\text{ s.t. }\xi _i \geq \sqrt{\log n} \right) \\
            \geq & \sqrt{2\log n}\big( 1- \Psi(\sqrt{\log n}) \big) ^n\\
            \gtrsim & \sqrt{\log n}(1-1/n)^n \\
            \gtrsim & \sqrt{\log n}
        \end{align*}
        in which $ \Psi(\cdot) $ is the c.d.f. of standard normal distribution. And we used the property of mills ratio 
        \begin{align*}
            m(\delta ) := \dfrac{ 1-\Psi(\delta ) }{ \phi (\delta ) } \sim \dfrac{ 1 }{ \delta  }    \Rightarrow 1-\Psi(\sqrt{\log n}) \gtrsim \dfrac{ 1 }{ \sqrt{n\log n} } \geq \dfrac{ 1 }{ n }  
        \end{align*}
        (From MJW Exercise 2.2 or refer to \href{https://en.wikipedia.org/wiki/Mills_ratio}{Wikipedia})

        And if $ \xi _i $ are $ N(0,\sigma ^2) $, the bound would be $ \sigma \sqrt{\log n} $ (trivially by scaling).
        \end{lemma}
    \item  For $ \{p\}_{p\in \mathcal{M}}\subset \mathbb{R}^n $ we construct the following two gaussian processes:
    \begin{align*}
        X_p := & \left\langle p,w \right\rangle ,\quad w\sim N(0,I)\\
        Y_p \mathop{ \sim }\limits^{i.i.d.} & N(0,\varepsilon ^2/2)
    \end{align*}

    Using the construction we have $ \forall p,q \in \mathcal{M} $:
    \begin{align*}
        \mathbb{E}\left[ (X_p-X_q)^2 \right] = & \left\Vert p-q \right\Vert _2^2 \geq \varepsilon ^2 = \mathbb{E}\left[ (Y_p-Y_q)^2 \right]      
    \end{align*}
    since $ \mathcal{M} $ is a packing set. 

    Then we note the following inequality:
    \begin{align*}
        \mathbb{E}\left[ \sup_{p\in\mathcal{M}}X_p \right] \mathop{ \geq  }\limits^{(ii)}  \mathbb{E}\left[ \sup_{p\in\mathcal{M}}Y_p \right] \mathop{ \gtrsim }\limits^{(iii)} \varepsilon \sqrt{\log \left\vert \mathcal{M} \right\vert } 
    \end{align*}
    in which $ (ii) $ is due to Sudakov-Fernique inequality, and $ (iii) $ is due to Lemma \ref{lem:1}.
    \item Now we upper bound $ \mathbb{E}\left[ \sup_{p\in\mathcal{M}}X_p \right] $ as follows: Since $ P $ is a polytope and $ \mathcal{M}\subset P $, we have
    \begin{align*}
        \mathbb{E}\left[ \sup_{p\in\mathcal{M}}X_p \right] \leq &\mathbb{E}\left[ \sup_{p\in P}X_p \right] = \mathbb{E}\left[ \sup_{p\in \text{vertices of }P}\left\langle p,w \right\rangle  \right] \mathop{ \lesssim }\limits^{(iv)}  \sqrt{\log N}
    \end{align*}
    in which $ (iv) $ used the maximal inequality by noticing that $ \left\langle p,w \right\rangle  $ are sub-gaussian with parameter $ 1 $.
\end{enumerate}

Putting the above steps together, we have
\begin{align*}
    \varepsilon \sqrt{\log \left\vert \mathcal{N} \right\vert }  \mathop{ \leq }\limits^{(i)}  \varepsilon \sqrt{\log \left\vert \mathcal{M} \right\vert } \mathop{ \lesssim }\limits^{(iii)} \mathbb{E}\left[ \sup_{p\in\mathcal{M}}Y_p \right]  \mathop{ \leq  }\limits^{(ii)} \mathbb{E}\left[ \sup_{p\in\mathcal{M}}X_p \right] \mathop{ \lesssim }\limits^{(iv)} \sqrt{\log N}
\end{align*}
i.e. for some absolute constant $ C $, we have
\begin{align*}
    \left\vert \mathcal{N}(P,\varepsilon ,\left\Vert \, \cdot \,  \right\Vert _2) \right\vert \leq N^{C/\varepsilon ^2}
\end{align*}





    



















\section{}

\subsection{}
Note that we have 
\begin{align*}
    \left\Vert y-X\hat{\theta } \right\Vert _2^2 \leq \left\Vert y-X\theta ^* \right\Vert _2^2
\end{align*}
which gives
\begin{align*}
     \left\Vert X(\hat{\theta }-\theta ^*) \right\Vert _2^2 \leq 2 w'\left( X(\hat{\theta }-\theta ^*) \right) \Rightarrow  \left\Vert X(\hat{\theta }-\theta ^*) \right\Vert _2 \leq 2 w'\dfrac{ X(\hat{\theta }-\theta ^*)  }{ \left\Vert X(\hat{\theta }-\theta ^*) \right\Vert _2 } 
\end{align*}

\subsection{}

Note that $ \hat{\theta }-\theta ^* $ should be $ 2s $-sparse, and $ X(\hat{\theta }-\theta ^*)\in \mathrm{col}(X_{\mathrm{ span }(\hat{\theta }\cup \theta ^*) }) $, we thus have
\begin{align*}
    w'\dfrac{ X(\hat{\theta }-\theta ^*)  }{ \left\Vert X(\hat{\theta }-\theta ^*) \right\Vert _2 } \leq \mathop{ \sup  }\limits_{\left\vert S  \right\vert \leq 2s }\mathop{ \sup  }\limits_{v_S\in \mathbb{S}^{n-1}, v_S\in \mathrm{ col  } (X_S)} w'v_S 
\end{align*}




\subsection{}
We have for $ w\mapsto \mathop{ \sup  }\limits_{v_S\in \mathbb{S}^{n-1}, v_S\in \mathrm{ col  } (X_S)} w'v_S := g(w) $:
\begin{align*}
    g(w)=g(w_S + w_{S^\complement}) = g(w_S)= \left\Vert w_S  \right\Vert _2
\end{align*}
in which $ w_S $ is the projection of $ w $ onto $ \mathrm{ col  } (X_S) $, and $ w_{S^\complement} $ is  its orthogonal complement. Further since $ w\sim N(0,\sigma ^2 I) $, we can consider 
\begin{align*}
    w = P\tilde{w} = P_S\tilde{w}_S + P_{S^\complement}\tilde{w}_{S^\complement} ,\quad P \in \mathrm{SO}(n)
\end{align*}
i.e. decompose $ w $ into $ w_S $ and $ w_{S^\complement} $, with each following gaussian distribution.

Then for $ w\sim N(0,\sigma ^2I) $ we have 
\begin{align*}
    \mathbb{E}\left[ g(w) \right] = & \mathbb{E}\left[ \left\Vert w_S \right\Vert _2 \right] = \mathbb{E}\left[ \left\Vert P_S\tilde{w}_S \right\Vert _2 \right]  = \sigma \mathbb{E}\left[ \sqrt{\chi^2_{2s}}  \right]  \leq \sigma \sqrt{\mathbb{E}\chi^2_{2s}}= \sigma \sqrt{2s}
\end{align*}


Then we note that for any $ w,y \in \mathbb{R}^d $:
\begin{align*}
    \left\vert g(w)-g(y) \right\vert =\left\Vert w_S-y_S \right\Vert _2 \leq \left\Vert w-y \right\Vert _2
\end{align*}
which means that $ g(w) $ is 1-Lipschitz. Then we can apply the concentration inequality for Lipschitz function to obtain that 
\begin{align*}
    \mathbb{P}\left( \left\vert g(w) -\mathbb{E}g(w) \right\vert \geq t \right) \leq 2\exp\left( -\dfrac{ t^2 }{ 2\sigma ^2 }  \right)
     \Rightarrow \mathbb{P}\left( \mathop{ \sup  }\limits_{v_S\in \mathbb{S}^{n-1}, v_S\in \mathrm{ col  } (X_S)} w'v_S \geq \sigma \sqrt{2s} + t \right) \leq 2\exp\left( -\dfrac{ t^2 }{ 2\sigma ^2 }  \right)
\end{align*}
letting $ \delta  = 2\exp\left( -\dfrac{ t^2 }{ 2\sigma ^2 }  \right) $ we have:
\begin{align*}
    \mathop{ \sup  }\limits_{v_S\in \mathbb{S}^{n-1}, v_S\in \mathrm{ col  } (X_S)} w'v_S \leq \sigma \bigl( \sqrt{2s} + \sqrt{2\log (2/\delta )} \bigr),\quad \text{w.p. } \geq 1-\delta .
\end{align*}


\subsection{}
Using union bound on $ \{S\subset [d]: \left\vert S  \right\vert \leq 2s\} $ we have:
\begin{align*}
    \mathop{ \sup  }\limits_{\left\vert S  \right\vert \leq 2s }\mathop{ \sup  }\limits_{v_S\in \mathbb{S}^{n-1}, v_S\in \mathrm{ col  } (X_S)} w'v_S \leq \sigma \bigl( \sqrt{2s} + \sqrt{2\log (2/\delta )} \bigr)
\end{align*}
with probability at least 
\begin{align*}
    1- \delta \sum_{j=1}^{2s} \binom{d}{j} \geq 1- \delta \bigl(\dfrac{ ed }{ 2s } \bigr)^{2s}
\end{align*}
then we obtain the bound
\begin{align*}
    \left\Vert X(\hat{\theta }-\theta ^*) \right\Vert _2 \leq 2w'\dfrac{ X(\hat{\theta }-\theta ^*)  }{ \left\Vert X(\hat{\theta }-\theta ^*) \right\Vert _2 } \leq 2\sigma \bigl( \sqrt{2s} + \sqrt{2\log (2/\delta )} \bigr)  ,\quad \text{w.p. at least } 1- \delta \bigl(\dfrac{ ed }{ 2s } \bigr)^{2s}
\end{align*}


\textbf{Remark:} We may also make re-labelling $ \delta (ed/2s)^2s \mapsto \delta $ to obtain a probability bound of $ 1-\delta $:
\begin{align*}
    \left\Vert X(\hat{\theta }-\theta ^*) \right\Vert _2 \leq&  2\sigma \bigl( \sqrt{2s} + \sqrt{2\log (2/\delta ) + 2s\log (ed/2s)} \bigr) \\
    \lesssim & \sigma \left( \sqrt{s} + \sqrt{\log\dfrac{ 1 }{ \delta  } } + \sqrt{s\log\dfrac{ d }{ s } } \right) ,\quad \text{w.p. at least } 1- \delta
\end{align*}



































\end{document}